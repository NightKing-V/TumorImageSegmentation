{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf737868-d62f-466b-91d7-54b5b1185cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Correct path to where patient folders are stored\n",
    "data_path = r\"C:/Users/N.Kaushalee/Desktop/Final year project/Data sets/archive\"\n",
    "\n",
    "# Example patient\n",
    "patient_id = \"BraTS2021_00495\"\n",
    "patient_path = os.path.join(data_path, patient_id)\n",
    "\n",
    "# Path to files inside the patient's folder\n",
    "flair_path = os.path.join(patient_path, patient_id + \"_flair.nii.gz\")\n",
    "t1_path = os.path.join(patient_path, patient_id + \"_t1.nii.gz\")\n",
    "t1ce_path = os.path.join(patient_path, patient_id + \"_t1ce.nii.gz\")\n",
    "t2_path = os.path.join(patient_path, patient_id + \"_t2.nii.gz\")\n",
    "seg_path = os.path.join(patient_path, patient_id + \"_seg.nii.gz\")\n",
    "\n",
    "# Load and display\n",
    "flair = nib.load(flair_path).get_fdata()\n",
    "seg = nib.load(seg_path).get_fdata()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(flair[:, :, 80], cmap=\"gray\")\n",
    "plt.title(\"FLAIR\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(seg[:, :, 80], cmap=\"gray\")\n",
    "plt.title(\"Segmentation\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe92fd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for cv2\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6507acc-de51-401c-89d0-2457881d425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72810557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BraTS2021_00000\n",
      "BraTS2021_00002\n",
      "BraTS2021_00003\n",
      "BraTS2021_00005\n",
      "BraTS2021_00006\n",
      "BraTS2021_00008\n",
      "BraTS2021_00009\n",
      "BraTS2021_00011\n",
      "BraTS2021_00012\n",
      "BraTS2021_00014\n",
      "BraTS2021_00016\n",
      "BraTS2021_00017\n",
      "BraTS2021_00018\n",
      "BraTS2021_00019\n",
      "BraTS2021_00020\n",
      "BraTS2021_00021\n",
      "BraTS2021_00022\n",
      "BraTS2021_00024\n",
      "BraTS2021_00025\n",
      "BraTS2021_00026\n",
      "BraTS2021_00028\n",
      "BraTS2021_00030\n",
      "BraTS2021_00031\n",
      "BraTS2021_00032\n",
      "BraTS2021_00033\n",
      "BraTS2021_00035\n",
      "BraTS2021_00036\n",
      "BraTS2021_00043\n",
      "BraTS2021_00044\n",
      "BraTS2021_00045\n",
      "BraTS2021_00046\n",
      "BraTS2021_00048\n",
      "BraTS2021_00049\n",
      "BraTS2021_00051\n",
      "BraTS2021_00052\n",
      "BraTS2021_00053\n",
      "BraTS2021_00054\n",
      "BraTS2021_00056\n",
      "BraTS2021_00058\n",
      "BraTS2021_00059\n",
      "BraTS2021_00060\n",
      "BraTS2021_00061\n",
      "BraTS2021_00062\n",
      "BraTS2021_00063\n",
      "BraTS2021_00064\n",
      "BraTS2021_00066\n",
      "BraTS2021_00068\n",
      "BraTS2021_00070\n",
      "BraTS2021_00071\n",
      "BraTS2021_00072\n",
      "BraTS2021_00074\n",
      "BraTS2021_00077\n",
      "BraTS2021_00078\n",
      "BraTS2021_00081\n",
      "BraTS2021_00084\n",
      "BraTS2021_00085\n",
      "BraTS2021_00087\n",
      "BraTS2021_00088\n",
      "BraTS2021_00089\n",
      "BraTS2021_00090\n",
      "BraTS2021_00094\n",
      "BraTS2021_00095\n",
      "BraTS2021_00096\n",
      "BraTS2021_00097\n",
      "BraTS2021_00098\n",
      "BraTS2021_00099\n",
      "BraTS2021_00100\n",
      "BraTS2021_00101\n",
      "BraTS2021_00102\n",
      "BraTS2021_00103\n",
      "BraTS2021_00104\n",
      "BraTS2021_00105\n",
      "BraTS2021_00106\n",
      "BraTS2021_00107\n",
      "BraTS2021_00108\n",
      "BraTS2021_00109\n",
      "BraTS2021_00110\n",
      "BraTS2021_00111\n",
      "BraTS2021_00112\n",
      "BraTS2021_00113\n",
      "BraTS2021_00115\n",
      "BraTS2021_00116\n",
      "BraTS2021_00117\n",
      "BraTS2021_00118\n",
      "BraTS2021_00120\n",
      "BraTS2021_00121\n",
      "BraTS2021_00122\n",
      "BraTS2021_00123\n",
      "BraTS2021_00124\n",
      "BraTS2021_00126\n",
      "BraTS2021_00127\n",
      "BraTS2021_00128\n",
      "BraTS2021_00130\n",
      "BraTS2021_00131\n",
      "BraTS2021_00132\n",
      "BraTS2021_00133\n",
      "BraTS2021_00134\n",
      "BraTS2021_00136\n",
      "BraTS2021_00137\n",
      "BraTS2021_00138\n",
      "BraTS2021_00139\n",
      "BraTS2021_00140\n",
      "BraTS2021_00142\n",
      "BraTS2021_00143\n",
      "BraTS2021_00144\n",
      "BraTS2021_00146\n",
      "BraTS2021_00147\n",
      "BraTS2021_00148\n",
      "BraTS2021_00149\n",
      "BraTS2021_00150\n",
      "BraTS2021_00151\n",
      "BraTS2021_00152\n",
      "BraTS2021_00154\n",
      "BraTS2021_00155\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Define preprocessing function\n",
    "def load_and_preprocess(patient_path, patient_id, image_size=(128, 128)):\n",
    "    # List of MRI modalities\n",
    "    modalities = ['flair', 't1', 't1ce', 't2']\n",
    "    \n",
    "    # List to store all modality images\n",
    "    images = []\n",
    "    \n",
    "    # Loop over each modality to load the MRI images\n",
    "    for modality in modalities:\n",
    "        # Construct file path for each modality (e.g., flair, t1, t1ce, t2)\n",
    "        file_path = os.path.join(patient_path, f\"{patient_id}_{modality}.nii.gz\")\n",
    "        \n",
    "        # Load the MRI image using nibabel\n",
    "        img = nib.load(file_path).get_fdata()\n",
    "        \n",
    "        # Normalize the image: Scale the pixel values to range 0-1\n",
    "        img = (img - img.min()) / (img.max() - img.min())  # Normalize the image\n",
    "        \n",
    "        # Optionally rotate (if needed) and resize the image\n",
    "        img = np.rot90(img, k=1, axes=(0, 1))  # Rotate if images are not aligned correctly\n",
    "        images.append(img)  # Append the image to the list of images\n",
    "    \n",
    "    # Stack all 4 modalities (FLAIR, T1, T1CE, T2) into one 4-channel image\n",
    "    images = np.stack(images, axis=-1)  # Shape: (H, W, Slices, 4)\n",
    "    images = np.transpose(images, (2, 0, 1, 3))  # Shape: (Slices, H, W, 4)\n",
    "\n",
    "    # Load the segmentation mask\n",
    "    seg_path = os.path.join(patient_path, f\"{patient_id}_seg.nii.gz\")\n",
    "    mask = nib.load(seg_path).get_fdata()\n",
    "    \n",
    "    # Normalize and rotate the mask (segmentation is binary)\n",
    "    mask = np.rot90(mask, k=1, axes=(0, 1))\n",
    "    mask = np.transpose(mask, (2, 0, 1))  # Shape: (Slices, H, W)\n",
    "\n",
    "    # Resize images and masks to the target size (e.g., 128x128)\n",
    "    X = []  # Input data (images)\n",
    "    Y = []  # Output data (masks)\n",
    "    \n",
    "    for i in range(images.shape[0]):  # Iterate over all slices\n",
    "        # Resize each slice of the images (input MRI modalities)\n",
    "        img_resized = cv2.resize(images[i], image_size, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Resize the corresponding mask (segmentation)\n",
    "        mask_resized = cv2.resize(mask[i], image_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        X.append(img_resized)  # Append the resized input image\n",
    "        Y.append(mask_resized)  # Append the resized mask\n",
    "    \n",
    "    X = np.array(X)  # Shape: (num_slices, 128, 128, 4)\n",
    "    Y = np.array(Y)  # Shape: (num_slices, 128, 128)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "# Example usage with your dataset path\n",
    "data_path = \"archive/BraTS2021_Training_Data\"\n",
    "# patient_id = \"BraTS2021_00495\"  # Change this if you want to process another patient\n",
    "# patient_path = os.path.join(data_path, patient_id)\n",
    "\n",
    "# # Preprocess the data for the given patient\n",
    "# X, Y = load_and_preprocess(patient_path, patient_id)\n",
    "\n",
    "results = []\n",
    "\n",
    "for folder_name in os.listdir(data_path):\n",
    "    patient_path = os.path.join(data_path, folder_name)\n",
    "\n",
    "    if os.path.isdir(patient_path):\n",
    "        patient_id = folder_name\n",
    "        print(folder_name)\n",
    "        X, Y = load_and_preprocess(patient_path, patient_id)\n",
    "        results.append((patient_id, X, Y))\n",
    "\n",
    "\n",
    "# Check the shapes of the preprocessed data\n",
    "print(\"Input shape:\", X.shape)  # (num_slices, 128, 128, 4)\n",
    "print(\"Mask shape:\", Y.shape)   # (num_slices, 128, 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bbaea5-634e-4e19-ae9d-835d7edff865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Shuffle the patients (for randomness)\n",
    "results = shuffle(results, random_state=42)\n",
    "\n",
    "# Define how many patients for each split\n",
    "num_train = 70\n",
    "num_val = 20\n",
    "num_test = 10\n",
    "\n",
    "# Split by number of patients\n",
    "train_patients = results[:num_train]\n",
    "val_patients = results[num_train:num_train + num_val]\n",
    "test_patients = results[num_train + num_val:num_train + num_val + num_test]\n",
    "\n",
    "# Helper function to flatten the data\n",
    "def extract_X_Y(patients):\n",
    "    X = np.concatenate([x for _, x, _ in patients], axis=0)\n",
    "    Y = np.concatenate([y for _, _, y in patients], axis=0)\n",
    "    return X, Y\n",
    "\n",
    "# Prepare datasets\n",
    "X_train, Y_train = extract_X_Y(train_patients)\n",
    "X_val, Y_val     = extract_X_Y(val_patients)\n",
    "X_test, Y_test   = extract_X_Y(test_patients)\n",
    "\n",
    "# Check shapes\n",
    "print(\"Train X:\", X_train.shape, \"Y:\", Y_train.shape)\n",
    "print(\"Val X:  \", X_val.shape,   \"Y:\", Y_val.shape)\n",
    "print(\"Test X: \", X_test.shape,  \"Y:\", Y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3286c76a-420b-4ca9-bda9-5714c197f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_unet(input_size=(128, 128, 4)):\n",
    "    inputs = layers.Input(input_size)\n",
    "\n",
    "    # Contracting path (Encoder)\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "    # Expansive path (Decoder)\n",
    "    up1 = layers.UpSampling2D((2, 2))(conv4)\n",
    "    up1 = layers.concatenate([up1, conv3], axis=-1)\n",
    "    conv5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up1)\n",
    "    conv5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up2 = layers.UpSampling2D((2, 2))(conv5)\n",
    "    up2 = layers.concatenate([up2, conv2], axis=-1)\n",
    "    conv6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up2)\n",
    "    conv6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up3 = layers.UpSampling2D((2, 2))(conv6)\n",
    "    up3 = layers.concatenate([up3, conv1], axis=-1)\n",
    "    conv7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up3)\n",
    "    conv7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv7)\n",
    "\n",
    "    # Build the model\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Build U-Net model\n",
    "model = build_unet(input_size=(128, 128, 4))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summarize the model architecture\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd92d9e2-51dc-4b40-9a76-36b7e88b1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using explicit validation data\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=10,\n",
    "    batch_size=4,\n",
    "    validation_data=(X_val, Y_val)  # <-- Use explicit validation set\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2facecd-ff28-4bbf-b8a7-1eccec7be690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12d5a2-df59-4368-8852-ec22c8882290",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('brain_tumor_segmentation_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10113d66-fc8b-4b34-b751-074848739325",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions.shape)  # (num_test_samples, 128, 128, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e28ca3-f1a3-402b-967c-8b332b50b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the first test image, its true mask, and predicted mask\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Input image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(X_test[0, :, :, 0], cmap='gray')  # First MRI modality (e.g., FLAIR)\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# True mask\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(Y_test[0], cmap='gray')\n",
    "plt.title(\"True Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Predicted mask\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(predictions[0, :, :, 0], cmap='gray')\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba630bc-6e15-40a5-846c-b20e87c760dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random test image and its corresponding mask\n",
    "index = np.random.randint(0, len(X_test))  # random index\n",
    "\n",
    "# Get the test image and ground truth mask\n",
    "test_image = X_test[index]\n",
    "true_mask = Y_test[index]\n",
    "\n",
    "# Predict the mask using the trained model\n",
    "predicted_mask = model.predict(np.expand_dims(test_image, axis=0))[0]  # Predict\n",
    "predicted_mask = (predicted_mask > 0.5).astype(np.uint8)  # Threshold\n",
    "\n",
    "# Plot the input image, ground truth mask, and predicted mask\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "# Input Image\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(test_image[:,:,0], cmap='gray')\n",
    "plt.title('Input MRI Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Ground Truth Mask\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(true_mask, cmap='gray')  # No third index here\n",
    "plt.title('Ground Truth Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "# Predicted Mask\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(predicted_mask[:,:,0], cmap='gray')\n",
    "plt.title('Predicted Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc9ffce-9a37-4a27-b566-391588eec35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sum of ground truth mask: {np.sum(true_mask)}\")\n",
    "print(f\"Sum of predicted mask: {np.sum(predicted_mask)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d5903-1026-41db-9d9b-298bc2b9151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Dice similarity coefficient between two binary masks.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (numpy array): Ground truth mask (binary)\n",
    "    y_pred (numpy array): Predicted mask (binary)\n",
    "    \n",
    "    Returns:\n",
    "    float: Dice similarity score\n",
    "    \"\"\"\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    \n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    dice_score = (2. * intersection) / (np.sum(y_true_f) + np.sum(y_pred_f))\n",
    "    return dice_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b776bfe-7f80-4143-9b2f-aa8430e7e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have X_test (input images) and y_test (ground truth masks)\n",
    "dice_scores = []\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "for i in range(len(X_test)):\n",
    "    test_image = X_test[i]\n",
    "    true_mask = Y_test[i]\n",
    "    \n",
    "    # Make predictions with the model\n",
    "    predicted_mask = model.predict(np.expand_dims(test_image, axis=0))[0]\n",
    "    \n",
    "    # Convert the predicted mask to binary (0 or 1)\n",
    "    predicted_mask = (predicted_mask > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Compute the Dice similarity coefficient\n",
    "    dice_score = dice_coefficient(true_mask, predicted_mask)\n",
    "    dice_scores.append(dice_score)\n",
    "\n",
    "# Calculate the average Dice score over the test set\n",
    "average_dice_score = np.mean(dice_scores)\n",
    "print(f\"Average Dice Similarity Score: {average_dice_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61802e1d-21d9-43b1-89f0-21ba31e69afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4843f8-23e0-4b44-b134-7a0bdf3cea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage.transform import rotate, resize\n",
    "\n",
    "def augment_data(image, mask):\n",
    "    # Apply random rotation\n",
    "    angle = np.random.uniform(-15, 15)\n",
    "    image = rotate(image, angle, mode='wrap')\n",
    "    mask = rotate(mask, angle, mode='wrap')\n",
    "\n",
    "    # Random zoom\n",
    "    zoom_factor = np.random.uniform(0.8, 1.2)\n",
    "    image = resize(image, (image.shape[0] * zoom_factor, image.shape[1] * zoom_factor, image.shape[2] * zoom_factor), mode='constant')\n",
    "    mask = resize(mask, (mask.shape[0] * zoom_factor, mask.shape[1] * zoom_factor, mask.shape[2] * zoom_factor), mode='constant')\n",
    "\n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098457f-852a-4901-8b20-12dfb39d2224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, new_shape=(128, 128, 128)):\n",
    "    # Normalize to 0-1\n",
    "    image = image / np.max(image)\n",
    "    # Resize the image to the desired shape\n",
    "    image = resize(image, new_shape)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e002aaf9-1521-4379-92cb-f08724d4957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def unet_3d(input_size=(128, 128, 128, 1)):\n",
    "    inputs = layers.Input(input_size)\n",
    "    # Downsampling path (contracting path)\n",
    "    conv1 = layers.Conv3D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    pool1 = layers.MaxPooling3D(2)(conv1)\n",
    "\n",
    "    conv2 = layers.Conv3D(64, 3, activation='relu', padding='same')(pool1)\n",
    "    pool2 = layers.MaxPooling3D(2)(conv2)\n",
    "\n",
    "    # Bottom layer\n",
    "    conv3 = layers.Conv3D(128, 3, activation='relu', padding='same')(pool2)\n",
    "\n",
    "    # Upsampling path (expanding path)\n",
    "    up1 = layers.UpSampling3D(2)(conv3)\n",
    "    conv4 = layers.Conv3D(64, 3, activation='relu', padding='same')(up1)\n",
    "\n",
    "    up2 = layers.UpSampling3D(2)(conv4)\n",
    "    conv5 = layers.Conv3D(32, 3, activation='relu', padding='same')(up2)\n",
    "\n",
    "    output = layers.Conv3D(1, 1, activation='sigmoid', padding='same')(conv5)\n",
    "\n",
    "    model = models.Model(inputs, output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be66b7-588e-4616-8f78-9c09f9b9cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_3d()\n",
    "model.fit(train_data, train_labels, validation_data=(val_data, val_labels), epochs=50, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec4c855-e551-4635-9689-c4e11efe971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection) / (np.sum(y_true) + np.sum(y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
